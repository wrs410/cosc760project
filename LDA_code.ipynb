{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#stuff for LDA topic modeling of tweets\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.read_csv('bmore.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):  \n",
    "    pat1 = r'@[^ ]+'                   \n",
    "    pat2 = r'https?://[A-Za-z0-9./]+'  \n",
    "    pat3 = r'\\'s'                      \n",
    "    pat4 = r'\\#\\w+'                     \n",
    "    pat5 = r'&amp '                     \n",
    "    pat6 = r'[^A-Za-z\\s]'               \n",
    "    combined_pat = r'|'.join((pat1, pat2,pat3,pat4,pat5, pat6))\n",
    "    text = re.sub(combined_pat,\"\",text).lower()\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing lemmatizer\n",
    "print(WordNetLemmatizer().lemmatize('went', pos = 'v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original word</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>caresses</td>\n",
       "      <td>caress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flies</td>\n",
       "      <td>fli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dies</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mules</td>\n",
       "      <td>mule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>denied</td>\n",
       "      <td>deni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>died</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>agreed</td>\n",
       "      <td>agre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>owned</td>\n",
       "      <td>own</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>humbled</td>\n",
       "      <td>humbl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sized</td>\n",
       "      <td>size</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>meeting</td>\n",
       "      <td>meet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>stating</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>siezing</td>\n",
       "      <td>siez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>itemization</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sensational</td>\n",
       "      <td>sensat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>traditional</td>\n",
       "      <td>tradit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>reference</td>\n",
       "      <td>refer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>colonizer</td>\n",
       "      <td>colon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>plotted</td>\n",
       "      <td>plot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original word stemmed\n",
       "0       caresses  caress\n",
       "1          flies     fli\n",
       "2           dies     die\n",
       "3          mules    mule\n",
       "4         denied    deni\n",
       "5           died     die\n",
       "6         agreed    agre\n",
       "7          owned     own\n",
       "8        humbled   humbl\n",
       "9          sized    size\n",
       "10       meeting    meet\n",
       "11       stating   state\n",
       "12       siezing    siez\n",
       "13   itemization    item\n",
       "14   sensational  sensat\n",
       "15   traditional  tradit\n",
       "16     reference   refer\n",
       "17     colonizer   colon\n",
       "18       plotted    plot"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing stemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "original_words = ['caresses', 'flies', 'dies', 'mules', 'denied','died', 'agreed', 'owned', \n",
    "           'humbled', 'sized','meeting', 'stating', 'siezing', 'itemization','sensational', \n",
    "           'traditional', 'reference', 'colonizer','plotted']\n",
    "singles = [stemmer.stem(plural) for plural in original_words]\n",
    "\n",
    "pd.DataFrame(data={'original word':original_words, 'stemmed':singles })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text preprocess\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "# Tokenize and lemmatize\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(text) :\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original document: \n",
      "['This', 'disk', 'has', 'failed', 'many', 'times.', 'I', 'would', 'like', 'to', 'get', 'it', 'replaced.']\n",
      "\n",
      "\n",
      "Tokenized and lemmatized document: \n",
      "['disk', 'fail', 'time', 'like', 'replac']\n"
     ]
    }
   ],
   "source": [
    "# Testing preprocessing function\n",
    "\n",
    "doc_sample = 'This disk has failed many times. I would like to get it replaced.'\n",
    "\n",
    "print(\"Original document: \")\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print(\"\\n\\nTokenized and lemmatized document: \")\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clean = [] \n",
    "\n",
    "for doc in df.text:\n",
    "    text_clean.append(preprocess(doc))\n",
    "\n",
    "#Create dictionary of lemmatized words\n",
    "dictionary = gensim.corpora.Dictionary(text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 baltimorean\n",
      "1 eternal\n",
      "2 forev\n",
      "3 francisco\n",
      "4 pelosi\n",
      "5 peopl\n",
      "6 repres\n",
      "7 speaker\n",
      "8 appropri\n",
      "9 barrier\n",
      "10 field\n"
     ]
    }
   ],
   "source": [
    "#Checking dictionary created\n",
    "\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create bag of words from dictionary\n",
    "twit_bag = [dictionary.doc2bow(doc) for doc in text_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twit_bag[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 0 (\"baltimorean\") appears 1 time.\n",
      "Word 1 (\"eternal\") appears 1 time.\n",
      "Word 2 (\"forev\") appears 1 time.\n",
      "Word 3 (\"francisco\") appears 1 time.\n",
      "Word 4 (\"pelosi\") appears 1 time.\n",
      "Word 5 (\"peopl\") appears 1 time.\n",
      "Word 6 (\"repres\") appears 1 time.\n",
      "Word 7 (\"speaker\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "#shows bag of words for first entry in dataset\n",
    "bow_doc_x = twit_bag[0]\n",
    "\n",
    "for i in range(len(bow_doc_x)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_x[i][0], \n",
    "                                                     dictionary[bow_doc_x[i][0]], \n",
    "                                                     bow_doc_x[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_lda = gensim.models.LdaMulticore(twit_bag, \n",
    "                                   num_topics = 15, \n",
    "                                   id2word = dictionary,                                    \n",
    "                                   passes = 10,\n",
    "                                   random_state = 1,\n",
    "                                   workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.030*\"water\" + 0.026*\"area\" + 0.021*\"test\" + 0.021*\"weather\" + 0.018*\"special\" + 0.017*\"expect\" + 0.017*\"point\" + 0.015*\"latest\" + 0.015*\"storm\" + 0.014*\"continu\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.033*\"covid\" + 0.029*\"case\" + 0.025*\"maryland\" + 0.021*\"report\" + 0.019*\"public\" + 0.019*\"death\" + 0.015*\"vaccin\" + 0.014*\"ann\" + 0.014*\"arundel\" + 0.013*\"believ\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.111*\"citi\" + 0.086*\"baltimor\" + 0.018*\"public\" + 0.018*\"mayor\" + 0.017*\"council\" + 0.015*\"meet\" + 0.013*\"hear\" + 0.012*\"board\" + 0.012*\"state\" + 0.011*\"announc\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.080*\"polic\" + 0.043*\"baltimor\" + 0.042*\"shoot\" + 0.030*\"offic\" + 0.025*\"yearold\" + 0.022*\"counti\" + 0.019*\"say\" + 0.019*\"charg\" + 0.018*\"investig\" + 0.018*\"kill\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.061*\"maryland\" + 0.031*\"elect\" + 0.029*\"raven\" + 0.025*\"vote\" + 0.020*\"state\" + 0.014*\"counti\" + 0.013*\"democrat\" + 0.013*\"candid\" + 0.011*\"race\" + 0.011*\"earli\"\n",
      "\n",
      "\n",
      "Topic: 5 \n",
      "Words: 0.043*\"live\" + 0.031*\"news\" + 0.029*\"talk\" + 0.024*\"baltimor\" + 0.021*\"stori\" + 0.020*\"join\" + 0.019*\"tonight\" + 0.019*\"watch\" + 0.015*\"game\" + 0.015*\"week\"\n",
      "\n",
      "\n",
      "Topic: 6 \n",
      "Words: 0.062*\"includ\" + 0.034*\"mean\" + 0.030*\"warn\" + 0.025*\"north\" + 0.019*\"univers\" + 0.016*\"colleg\" + 0.014*\"wind\" + 0.014*\"attempt\" + 0.013*\"farm\" + 0.012*\"sever\"\n",
      "\n",
      "\n",
      "Topic: 7 \n",
      "Words: 0.042*\"leav\" + 0.034*\"media\" + 0.030*\"hall\" + 0.024*\"forc\" + 0.022*\"trial\" + 0.018*\"social\" + 0.016*\"davi\" + 0.016*\"didnt\" + 0.016*\"town\" + 0.015*\"press\"\n",
      "\n",
      "\n",
      "Topic: 8 \n",
      "Words: 0.031*\"beat\" + 0.022*\"year\" + 0.015*\"baltimor\" + 0.014*\"million\" + 0.014*\"jackson\" + 0.012*\"build\" + 0.012*\"question\" + 0.011*\"near\" + 0.010*\"time\" + 0.009*\"home\"\n",
      "\n",
      "\n",
      "Topic: 9 \n",
      "Words: 0.046*\"look\" + 0.041*\"like\" + 0.024*\"love\" + 0.023*\"read\" + 0.020*\"great\" + 0.015*\"think\" + 0.015*\"best\" + 0.013*\"time\" + 0.012*\"send\" + 0.011*\"friend\"\n",
      "\n",
      "\n",
      "Topic: 10 \n",
      "Words: 0.023*\"court\" + 0.021*\"hous\" + 0.018*\"say\" + 0.018*\"presid\" + 0.017*\"john\" + 0.013*\"judg\" + 0.013*\"trump\" + 0.012*\"biden\" + 0.011*\"feder\" + 0.010*\"rule\"\n",
      "\n",
      "\n",
      "Topic: 11 \n",
      "Words: 0.025*\"support\" + 0.022*\"baltimor\" + 0.020*\"work\" + 0.018*\"help\" + 0.018*\"communiti\" + 0.015*\"program\" + 0.013*\"busi\" + 0.011*\"month\" + 0.010*\"fund\" + 0.010*\"organ\"\n",
      "\n",
      "\n",
      "Topic: 12 \n",
      "Words: 0.100*\"school\" + 0.060*\"student\" + 0.056*\"thank\" + 0.027*\"want\" + 0.022*\"happen\" + 0.020*\"high\" + 0.019*\"learn\" + 0.018*\"event\" + 0.015*\"teacher\" + 0.014*\"staff\"\n",
      "\n",
      "\n",
      "Topic: 13 \n",
      "Words: 0.064*\"peopl\" + 0.041*\"know\" + 0.035*\"black\" + 0.030*\"good\" + 0.025*\"need\" + 0.022*\"say\" + 0.012*\"right\" + 0.012*\"thing\" + 0.010*\"dont\" + 0.010*\"go\"\n",
      "\n",
      "\n",
      "Topic: 14 \n",
      "Words: 0.024*\"baltimor\" + 0.022*\"park\" + 0.022*\"today\" + 0.017*\"updat\" + 0.016*\"inform\" + 0.016*\"center\" + 0.015*\"week\" + 0.015*\"communiti\" + 0.014*\"happi\" + 0.014*\"free\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in tweets_lda.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['main_topic'] = [int(str(sorted(tweets_lda[i],reverse=True,key=lambda x: x[1])[0][0]).zfill(3)) for i in twit_bag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>twitter_name</th>\n",
       "      <th>text</th>\n",
       "      <th>number_of_likes</th>\n",
       "      <th>number_of_retweets</th>\n",
       "      <th>main_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-11-18 02:52:03+00:00</td>\n",
       "      <td>Brandon M. Scott</td>\n",
       "      <td>MayorBMScott</td>\n",
       "      <td>speaker pelosi may represent the people of san...</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-11-18 02:52:02+00:00</td>\n",
       "      <td>Brandon M. Scott</td>\n",
       "      <td>MayorBMScott</td>\n",
       "      <td>so many of my peers can thank her for knocking...</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2022-11-18 02:52:02+00:00</td>\n",
       "      <td>Brandon M. Scott</td>\n",
       "      <td>MayorBMScott</td>\n",
       "      <td>in addition to being the first female speaker ...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2022-11-18 02:52:01+00:00</td>\n",
       "      <td>Brandon M. Scott</td>\n",
       "      <td>MayorBMScott</td>\n",
       "      <td>it brings us all great pride that a daughter o...</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2022-11-18 02:52:00+00:00</td>\n",
       "      <td>Brandon M. Scott</td>\n",
       "      <td>MayorBMScott</td>\n",
       "      <td>on behalf of the city of baltimore i want to c...</td>\n",
       "      <td>221</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       date            author  twitter_name  \\\n",
       "0         0.0  2022-11-18 02:52:03+00:00  Brandon M. Scott  MayorBMScott   \n",
       "1         1.0  2022-11-18 02:52:02+00:00  Brandon M. Scott  MayorBMScott   \n",
       "2         2.0  2022-11-18 02:52:02+00:00  Brandon M. Scott  MayorBMScott   \n",
       "3         3.0  2022-11-18 02:52:01+00:00  Brandon M. Scott  MayorBMScott   \n",
       "4         4.0  2022-11-18 02:52:00+00:00  Brandon M. Scott  MayorBMScott   \n",
       "\n",
       "                                                text number_of_likes  \\\n",
       "0  speaker pelosi may represent the people of san...              36   \n",
       "1  so many of my peers can thank her for knocking...              26   \n",
       "2  in addition to being the first female speaker ...               9   \n",
       "3  it brings us all great pride that a daughter o...              11   \n",
       "4  on behalf of the city of baltimore i want to c...             221   \n",
       "\n",
       "  number_of_retweets  main_topic  \n",
       "0                  4          12  \n",
       "1                  2           0  \n",
       "2                  0          10  \n",
       "3                  2           5  \n",
       "4                 12          10  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'so many of my peers can thank her for knocking down barriers in order to level the playing field only appropriate'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'phase  of the  st century schools program is set to begin with renovations for some of our moat'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.main_topic[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stay connected you never know where your favorite artists entrepreneurs and influencers might be next visit'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.main_topic[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('lda_bmore.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
